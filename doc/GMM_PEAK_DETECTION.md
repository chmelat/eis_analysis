# GMM Peak Detection v DRT spektrech

**Verze:** 1.6.0
**Datum:** 2025-12-12
**Implementace:** `eis_analysis_1_6.py`

## PÅ™ehled

Gaussian Mixture Models (GMM) poskytujÃ­ robustnÄ›jÅ¡Ã­ a objektivnÄ›jÅ¡Ã­ metodu pro detekci pÃ­kÅ¯ v DRT (Distribution of Relaxation Times) spektrech neÅ¾ tradiÄnÃ­ `scipy.signal.find_peaks`.

### KlÃ­ÄovÃ© vÃ½hody

1. **ExplicitnÃ­ hranice pÃ­kÅ¯**: Ï„ âˆˆ [Î¼-2Ïƒ, Î¼+2Ïƒ] poskytuje 95% confidence interval
2. **AutomatickÃ¡ dekonvoluce**: Separuje pÅ™ekrÃ½vajÃ­cÃ­ se pÃ­ky
3. **ObjektivnÃ­ vÃ½bÄ›r**: BIC (Bayesian Information Criterion) automaticky urÄÃ­ poÄet pÃ­kÅ¯
4. **Kvantifikace nejistoty**: Å Ã­Å™ka pÃ­kÅ¯ v log-prostoru (Ïƒ)
5. **PÅ™esnÄ›jÅ¡Ã­ odhady R_i**: Integrace gaussovskÃ½ch komponent mÃ­sto ad-hoc hranice

## PouÅ¾itÃ­

### ZÃ¡kladnÃ­ pouÅ¾itÃ­

```bash
# GMM detekce pÃ­kÅ¯ (mÃ­sto vÃ½chozÃ­ scipy metody)
python3 eis_analysis_1_6.py data.DTA --peak-method gmm
```

### S automatickou analÃ½zou

```bash
# KompletnÃ­ automatizace: GMM + auto-lambda + auto-circuit
python3 eis_analysis_1_6.py data.DTA --peak-method gmm --auto-lambda --auto-circuit

# S verbose vÃ½stupem pro diagnostiku
python3 eis_analysis_1_6.py data.DTA --peak-method gmm --auto-lambda -vv
```

### UloÅ¾enÃ­ vÃ½sledkÅ¯

```bash
# UloÅ¾it grafy a skrÃ½t display
python3 eis_analysis_1_6.py data.DTA --peak-method gmm --save results --no-show
```

## VÃ½stup

### Konzole

GMM vypÃ­Å¡e detailnÃ­ informace o kaÅ¾dÃ©m detekovanÃ©m pÃ­ku:

```
==================================================
GMM detekce pÃ­kÅ¯
==================================================
HledÃ¡m optimÃ¡lnÃ­ poÄet komponent v rozsahu (1, 6)
âœ“ OptimÃ¡lnÃ­ poÄet pÃ­kÅ¯: 2 (BIC=56.59)

DetekovanÃ© pÃ­ky (seÅ™azeno podle Ï„):
  PÃ­k 1:
    Ï„ = 9.11e-04 s (f = 1.75e+02 Hz)
    Hranice Ï„: [3.25e-04, 2.55e-03] s
    Å Ã­Å™ka (Ïƒ): 0.224 dekÃ¡d
    VÃ¡ha: 0.314
    R ~ 1876.67 Î©
  PÃ­k 2:
    Ï„ = 4.92e-02 s (f = 3.24e+00 Hz)
    Hranice Ï„: [1.72e-02, 1.41e-01] s
    Å Ã­Å™ka (Ïƒ): 0.228 dekÃ¡d
    VÃ¡ha: 0.686
    R ~ 4178.99 Î©
```

### Grafy (layout 2Ã—2)

PÅ™i pouÅ¾itÃ­ GMM metody se vytvoÅ™Ã­ 4 subploty:

**Top-left: DRT spektrum**
- StandardnÃ­ Î³(Ï„) graf
- ZÃ¡kladnÃ­ vizualizace distribuce

**Top-right: Rekonstrukce Nyquist**
- PorovnÃ¡nÃ­ dat vs DRT rekonstrukce
- Kontrola kvality fitu

**Bottom-left: GMM dekonvoluce**
- PÅ™ekryv jednotlivÃ½ch gaussovskÃ½ch komponent (barevnÄ› odliÅ¡enÃ©)
- VertikÃ¡lnÃ­ ÄÃ¡ry oznaÄujÃ­:
  - TeÄkovanÃ©: hranice pÃ­kÅ¯ (Î¼Â±2Ïƒ)
  - PÅ™eruÅ¡ovanÃ©: stÅ™ed pÃ­ku (Î¼)
- Legenda s Ï„ hodnotami pro kaÅ¾dÃ½ pÃ­k

**Bottom-right: BIC kÅ™ivka**
- Model selection diagnostika
- X-osa: poÄet komponent
- Y-osa: BIC hodnota (niÅ¾Å¡Ã­ = lepÅ¡Ã­)
- ÄŒervenÃ¡ hvÄ›zda: optimÃ¡lnÃ­ volba

## TechnickÃ© detaily

### Algoritmus

1. **Transformace**: DRT se fituje v logâ‚â‚€(Ï„) prostoru pro lepÅ¡Ã­ separaci pÃ­kÅ¯
2. **VÃ¡hovÃ¡nÃ­**: Body jsou replikovÃ¡ny podle Î³(Ï„) amplitudy (novÃ© v sklearn 1.8+)
3. **BIC optimalizace**: Testuje n=1 aÅ¾ n=6 komponent
4. **KonzervativnÃ­ vÃ½bÄ›r**: Preferuje jednoduÅ¡Å¡Ã­ model pokud BIC improvement < 10
5. **Parametry pÃ­kÅ¯**:
   - Î¼ (mean): pozice pÃ­ku v logâ‚â‚€(Ï„)
   - Ïƒ (std): Å¡Ã­Å™ka v logâ‚â‚€(Ï„) prostoru
   - w (weight): relativnÃ­ vÃ¡ha komponenty
   - R_estimate: plocha gaussiÃ¡nu = w Ã— Î³_max Ã— Ïƒ Ã— âˆš(2Ï€) Ã— ln(10)

### BIC formula

```
BIC(n) = -2Â·log(L) + kÂ·log(N)
```

kde:
- L = likelihood modelu s n komponentami
- k = poÄet parametrÅ¯ (3n pro GMM: Î¼, Ïƒ, w pro kaÅ¾dou komponentu)
- N = poÄet datovÃ½ch bodÅ¯

NiÅ¾Å¡Ã­ BIC = lepÅ¡Ã­ kompromis mezi fitem a sloÅ¾itostÃ­.

### SrovnÃ¡nÃ­ s scipy.find_peaks

| Vlastnost | `scipy.find_peaks` | GMM |
|-----------|-------------------|-----|
| PÅ™ekrÃ½vajÃ­cÃ­ se pÃ­ky | âŒ Jen jeden max | âœ… Dekonvoluce |
| Hranice pÃ­kÅ¯ | âŒ NedefinovanÃ© | âœ… Î¼Â±2Ïƒ (95% CI) |
| Å Ã­Å™ka pÃ­kÅ¯ | âŒ | âœ… Ïƒ v log-prostoru |
| Odhad R_i | ManuÃ¡lnÃ­ integrace | âœ… Z plochy gaussiÃ¡nu |
| Objektivita | âš ï¸ Hard thresholds | âœ… BIC |
| Rychlost | âœ…âœ… Velmi rychlÃ© | âœ… RychlÃ© (~1-2s) |
| ZÃ¡vislosti | scipy | sklearn |

## Integrace s auto-circuit

PÅ™i pouÅ¾itÃ­ `--auto-circuit`, GMM pÃ­ky se automaticky pouÅ¾ijÃ­ pro:

1. **PoÄet VoigtovÃ½ch ÄlÃ¡nkÅ¯**: Jeden ÄlÃ¡nek R||C pro kaÅ¾dÃ½ GMM pÃ­k
2. **Initial guess pro R_i**: PouÅ¾ije R_estimate z GMM
3. **Initial guess pro Ï„_i**: PouÅ¾ije Ï„_center z GMM
4. **Initial guess pro C_i**: VypoÄte C_i = Ï„_i / R_i

VÃ½sledek: VÃ½raznÄ› lepÅ¡Ã­ konvergence circuit fitu.

## PoÅ¾adavky

### Python balÃ­Äky

```bash
# NutnÃ© pro GMM
pip install scikit-learn --break-system-packages

# Nebo systemovÄ› (Debian/Ubuntu)
sudo apt install python3-sklearn
```

### Fallback

Pokud sklearn nenÃ­ dostupnÃ½:
- GMM metoda se automaticky pÅ™epne na `scipy.find_peaks`
- UÅ¾ivatel dostane warning zprÃ¡vu
- AnalÃ½za pokraÄuje s fallback metodou

## Kdy pouÅ¾Ã­t GMM vs scipy

### âœ… PouÅ¾ij GMM pokud:
- MÃ¡Å¡ pÅ™ekrÃ½vajÃ­cÃ­ se pÃ­ky
- PotÅ™ebujeÅ¡ pÅ™esnÃ© hranice pro fyzikÃ¡lnÃ­ interpretaci
- ChceÅ¡ objektivnÃ­ vÃ½bÄ›r poÄtu pÃ­kÅ¯
- PotÅ™ebujeÅ¡ publikovatelnÃ© vÃ½sledky s kvantifikacÃ­ nejistoty

### ğŸ”§ PouÅ¾ij scipy pokud:
- PÃ­ky jsou dobÅ™e separovanÃ©
- PotÅ™ebujeÅ¡ rychlou exploraci
- sklearn nenÃ­ dostupnÃ½
- StaÄÃ­ ti kvalitativnÃ­ analÃ½za

## PÅ™Ã­klady vÃ½stupÅ¯

### PÅ™Ã­klad 1: Dva dobÅ™e separovanÃ© pÃ­ky

```
Input: R1=1000Î©, Ï„1=1ms, R2=5000Î©, Ï„2=50ms
GMM output:
  PÃ­k 1: Ï„=0.91ms [0.33-2.6ms]  R~1877Î©
  PÃ­k 2: Ï„=49.2ms [17-141ms]    R~4179Î©
BIC: n=2 optimal (BIC=56.59)
```

### PÅ™Ã­klad 2: PÅ™ekrÃ½vajÃ­cÃ­ se pÃ­ky

```
Input: R1=2000Î©, Ï„1=5ms, R2=3000Î©, Ï„2=8ms (ÄÃ¡steÄnÃ½ pÅ™ekryv)
scipy: Detekuje 1 Å¡irokÃ½ pÃ­k pÅ™i Ï„~6ms
GMM: Separuje na 2 pÃ­ky pÅ™i Ï„1=4.8ms a Ï„2=8.3ms
```

## Limitace a budoucÃ­ vylepÅ¡enÃ­

### SouÄasnÃ© limitace

1. **GaussovskÃ½ pÅ™edpoklad**: ReÃ¡lnÃ© pÃ­ky mohou bÃ½t asymetrickÃ©
2. **Pouze kladnÃ© Î³**: ZatÃ­m nepodporuje zÃ¡pornÃ© pÃ­ky (induktivnÃ­ smyÄky)
3. **FixnÃ­ rozsah**: n=1 aÅ¾ n=6 komponent (mÅ¯Å¾e bÃ½t nedostateÄnÃ© pro sloÅ¾itÃ© systÃ©my)

### PlÃ¡novanÃ¡ vylepÅ¡enÃ­ (v1.7+)

- [ ] **Log-normÃ¡lnÃ­ smÄ›s**: LepÅ¡Ã­ pro asymetrickÃ© pÃ­ky
- [ ] **Signed GMM**: Podpora zÃ¡pornÃ½ch Î³ pro induktivnÃ­ procesy
- [ ] **Bayesian GMM**: Dirichlet Process pro automatickÃ½ poÄet komponent bez hornÃ­ meze
- [ ] **Uncertainty propagation**: Chyby R_i a C_i z GMM kovariancÃ­
- [ ] **L-curve visualization**: AlternativnÃ­ diagnostika k BIC

## Reference

### Teorie GMM

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer. Chapter 9.
- Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press. Chapter 11.

### BIC v kontextu regularizace

- Schwarz, G. (1978). "Estimating the dimension of a model". *Annals of Statistics* 6(2), 461-464.
- Burnham, K. P., & Anderson, D. R. (2004). *Multimodel Inference*. Springer.

### DRT aplikace

- Saccoccio, M. et al. (2014). "Optimal Regularization in Distribution of Relaxation Times applied to Electrochemical Impedance Spectroscopy". *Electrochimica Acta* 147, 470-482.

## Troubleshooting

### "ModuleNotFoundError: No module named 'sklearn'"

```bash
pip install scikit-learn --break-system-packages
```

### "GMM fit selhal pro n=X"

Obvykle neÅ¡kodnÃ© - nÄ›kterÃ© hodnoty n mohou selhat kvÅ¯li numerickÃ© nestabilitÄ›. GMM automaticky pÅ™eskoÄÃ­ tyto hodnoty.

### "VÅ¡echny GMM fity selhaly"

VzÃ¡cnÃ©, ale moÅ¾nÃ© pÅ™i:
- Velmi malÃ©m poÄtu bodÅ¯
- ExtrÃ©mnÄ› Å¡umnÃ½ch datech
- TÃ©mÄ›Å™ nulovÃ© Î³(Ï„)

Å˜eÅ¡enÃ­: AutomatickÃ½ fallback na scipy.find_peaks.

### GMM najde pÅ™Ã­liÅ¡ mnoho/mÃ¡lo pÃ­kÅ¯

Zkus:
1. ZmÄ›nit regularizaci Î» (mÃ©nÄ› pÃ­kÅ¯ â†’ zvÄ›tÅ¡i Î»)
2. PouÅ¾Ã­t `--auto-lambda` pro optimÃ¡lnÃ­ Î»
3. ZvÃ½Å¡it `--n-tau` pro lepÅ¡Ã­ rozliÅ¡enÃ­

## PÅ™Ã­spÄ›vky

MÃ¡te-li nÃ¡pady na vylepÅ¡enÃ­ GMM implementace:
- OtevÅ™ete issue na GitHubu
- NavrhnÄ›te pull request s vylepÅ¡enÃ­m
- SdÃ­lejte pÅ™Ã­klady dat kde GMM selhÃ¡vÃ¡

---

**Autor:** EIS analÃ½za toolkit v1.6
**Licence:** MIT (nebo dle projektu)
**Kontakt:** [vaÅ¡e email/GitHub]
